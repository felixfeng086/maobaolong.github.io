<?xml version="1.0" encoding="utf-8"?>
<search>
  
    
    <entry>
      <title></title>
      <url>%2Fgithub_blog%2F2016%2F12%2F23%2F%E6%8A%80%E6%9C%AF%E5%AD%A6%E4%B9%A0%2Fbigdata%2Fhive%2Fspark%2F</url>
      <content type="text"></content>
    </entry>

    
    <entry>
      <title></title>
      <url>%2Fgithub_blog%2F2016%2F12%2F23%2F%E6%8A%80%E6%9C%AF%E5%AD%A6%E4%B9%A0%2Fbigdata%2Fspark%2Fspark%2F</url>
      <content type="text"></content>
    </entry>

    
    <entry>
      <title></title>
      <url>%2Fgithub_blog%2F2016%2F12%2F22%2F%E6%8A%80%E6%9C%AF%E5%AD%A6%E4%B9%A0%2Fbigdata%2F%E5%B8%B8%E7%94%A8%E7%AB%AF%E5%8F%A3%2F</url>
      <content type="text"><![CDATA[Hadoop集群的各部分一般都会使用到多个端口，有些是daemon之间进行交互之用，有些是用于RPC访问以及HTTP访问。而随着Hadoop周边组件的增多，完全记不住哪个端口对应哪个应用，特收集记录如此，以便查询。 这里包含我们使用到的组件：HDFS, YARN, HBase, Hive, ZooKeeper: 组件 节点 默认端口 配置 用途说明 HDFS DataNode 50010 dfs.datanode.address datanode服务端口，用于数据传输 HDFS DataNode 50075 dfs.datanode.http.address http服务的端口 HDFS DataNode 50475 dfs.datanode.https.address https服务的端口 HDFS DataNode 50020 dfs.datanode.ipc.address ipc服务的端口 HDFS NameNode 50070 dfs.namenode.http-address http服务的端口 HDFS NameNode 50470 dfs.namenode.https-address https服务的端口 HDFS NameNode 8020 fs.defaultFS 接收Client连接的RPC端口，用于获取文件系统metadata信息。 HDFS journalnode 8485 dfs.journalnode.rpc-address RPC服务 HDFS journalnode 8480 dfs.journalnode.http-address HTTP服务 HDFS ZKFC 8019 dfs.ha.zkfc.port ZooKeeper FailoverController，用于NN HA YARN ResourceManager 8032 yarn.resourcemanager.address RM的applications manager(ASM)端口 YARN ResourceManager 8030 yarn.resourcemanager.scheduler.address scheduler组件的IPC端口 YARN ResourceManager 8031 yarn.resourcemanager.resource-tracker.address IPC YARN ResourceManager 8033 yarn.resourcemanager.admin.address IPC YARN ResourceManager 8088 yarn.resourcemanager.webapp.address http服务端口 YARN NodeManager 8040 yarn.nodemanager.localizer.address localizer IPC YARN NodeManager 8042 yarn.nodemanager.webapp.address http服务端口 YARN NodeManager 8041 yarn.nodemanager.address NM中container manager的端口 YARN JobHistory Server 10020 mapreduce.jobhistory.address IPC YARN JobHistory Server 19888 mapreduce.jobhistory.webapp.address http服务端口 HBase Master 60000 hbase.master.port IPC HBase Master 60010 hbase.master.info.port http服务端口 HBase RegionServer 60020 hbase.regionserver.port IPC HBase RegionServer 60030 hbase.regionserver.info.port http服务端口 HBase HQuorumPeer 2181 hbase.zookeeper.property.clientPort HBase-managed ZK mode，使用独立的ZooKeeper集群则不会启用该端口。 HBase HQuorumPeer 2888 hbase.zookeeper.peerport HBase-managed ZK mode，使用独立的ZooKeeper集群则不会启用该端口。 HBase HQuorumPeer 3888 hbase.zookeeper.leaderport HBase-managed ZK mode，使用独立的ZooKeeper集群则不会启用该端口。 Hive Metastore 9083 /etc/default/hive-metastore中export PORT=来更新默认端口 Hive HiveServer 10000 /etc/hive/conf/hive-env.sh中export HIVE_SERVER2_THRIFT_PORT=来更新默认端口 ZooKeeper Server 2181 /etc/zookeeper/conf/zoo.cfg中clientPort= 对客户端提供服务的端口 ZooKeeper Server 2888 /etc/zookeeper/conf/zoo.cfg中server.x=[hostname]:nnnnn[:nnnnn]，标蓝部分 follower用来连接到leader，只在leader上监听该端口。 ZooKeeper Server 3888 /etc/zookeeper/conf/zoo.cfg中server.x=[hostname]:nnnnn[:nnnnn]，标蓝部分 用于leader选举的。只在electionAlg是1,2或3(默认)时需要。 所有端口协议均基于TCP。 对于存在Web UI（HTTP服务）的所有hadoop daemon，有如下url： /logs日志文件列表，用于下载和查看 /logLevel允许你设定log4j的日志记录级别，类似于hadoop daemonlog /stacks所有线程的stack trace，对于debug很有帮助 /jmx服务端的Metrics，以JSON格式输出。 /jmx?qry=Hadoop:*会返回所有hadoop相关指标。/jmx?get=MXBeanName::AttributeName 查询指定bean指定属性的值，例如/jmx?get=Hadoop:service=NameNode,name=NameNodeInfo::ClusterId会返回ClusterId。这个请求的处理类：org.apache.hadoop.jmx.JMXJsonServlet 而特定的Daemon又有特定的URL路径特定相应信息。 NameNode:http://:50070/ /dfshealth.jspHDFS信息页面，其中有链接可以查看文件系统 /dfsnodelist.jsp?whatNodes=(DEAD|LIVE)显示DEAD或LIVE状态的datanode /fsck运行fsck命令，不推荐在集群繁忙时使用！ DataNode:http://:50075/ /blockScannerReport每个datanode都会指定间隔验证块信息]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[saltstack-minion]]></title>
      <url>%2Fgithub_blog%2F2016%2F12%2F16%2F%E6%8A%80%E6%9C%AF%E5%AD%A6%E4%B9%A0%2Fbigdata%2Fsaltstack-minion%2F</url>
      <content type="text"><![CDATA[salt命令列表saltsalt-apisalt-callsalt-cpsalt-keysalt-mastersalt-minionsalt-runsalt-sshsalt-unity 在minion上查看正在执行的任务，可以通过文件来查看ls /var/cache/salt/minion/procmaster的jobls /var/cache/salt/master/jobs/ master端的jobs，默认保存时间为24小时123root@salt-master:~# grep &quot;keep_jobs&quot; /etc/salt/master#keep_jobs: 24root@salt-master:~# 查看jobsalt-run jobs.active 查看历史jobsalt-run jobs.list_jobs | tail -n 16 查看某个任务的执行结果salt-run jobs.lookup_jid 20140625200258757661 某个结点执行命令salt ‘172.16.166.34’ cmd.run ‘ls ‘ 将本机的文件拷贝到 目标结点的/root/getIP.pysalt-cp ‘172.16.166.34’ ./getIP.py /root/getIP.py]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[树莓派接人体感应传感器]]></title>
      <url>%2Fgithub_blog%2F2016%2F12%2F15%2F%E6%8A%80%E6%9C%AF%E5%AD%A6%E4%B9%A0%2F%E6%A0%91%E8%8E%93%E6%B4%BE%2F%E6%A0%91%E8%8E%93%E6%B4%BE%E6%8E%A5%E4%BA%BA%E4%BD%93%E6%84%9F%E5%BA%94%E4%BC%A0%E6%84%9F%E5%99%A8%2F</url>
      <content type="text"><![CDATA[HC-SR501 感应模块简介 对照前面的参数以及电路图，找到下面的左右针脚正负极，中间的PIN为感应输出，感应到人体时，输出3.3V高电平，检测不到信号时输出0。同时还要求工作电压在4.5V-20V之间。恰好树莓派的P1编号中第2，4号PIN都是5V的电压，满足要求，所以这次我们要接5V的电压。 参数调节旋钮是用来扭动控制一些参数的。比如探测的延时时间，灵敏度等等。具体可以参看 HC -SR501的说明书。这里我们都使用默认值。 但是有一个关键的L H模式调节阀门要介绍一下，右上角有三个针脚，按照我实物照片，假定从上到下为123 。还有一个黄色的套接头，图中套接头接通了2 3号，代表了H模式，这个套接头是可以拔下来的，然后插到上面来，接通1 2号，代表了L模式。 L模式是不可重复触发，当探测到一次人体时，输出一次高电平，保持一段时间恢复低电平，在此期间如果还是检测到了人体也不再延长这个高电平的时间。等到低电平的封锁时间（前面默认是2.5S）过了以后才又开始检测。 H模式是可以重复触发，如果一直感应到人体时，会一直输出高电平，直到探测不到人体后保持小段时间然后恢复低电平。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[alluxio介绍与安装]]></title>
      <url>%2Fgithub_blog%2F2016%2F12%2F13%2F%E6%8A%80%E6%9C%AF%E5%AD%A6%E4%B9%A0%2Fbigdata%2Falluxio%2Falluxio%2F</url>
      <content type="text"><![CDATA[介绍 概念：是一个开源的基于内存的分布式存储系统，现在成为开源社区中成长最快的大数据开源项目之一。 公司简介 由项目的创建者李浩源以及来自UC Berkeley, Google, CMU, Palantir, Stanford, Yahoo等不同公司和学校的项目核心开发者组成。 完成750万 dollars 的A轮融资，由Andreessen Horowitz投资（硅谷最著名的VC之一，主要成员为网景公司创始人之一）。 作者：Mingche Su链接：https://zhuanlan.zhihu.com/p/20624086来源：知乎著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。 术语 Amazon AWS ：亚马逊AWS 云服务-中国领先的可扩展云计算平台 Amazon S3 ：是一种在Internet 上的云存储服务。 要上传数据（照片、视频、文档等），请首先在一个AWS 区域中创建存储桶。 然后，您可以将任何数量的对象上传到该存储桶。 安装 解压 12$ tar -xzf alluxio-1.3.0-bin.tar.gz$ cd alluxio-1.3.0 生成配置文件 1./bin/alluxio bootstrapConf localhost 格式化Alluxio我们格式化Alluxio为启动Alluxio做准备。如下命令会格式化Alluxio的日志和worker存储目录，以便接下来启动master和worker。1./bin/alluxio format 启动我们启动Alluxio！Alluxio默认配置成在localhost启动master和worker。我们可以用如下命令在localhost启动Alluxio：1./bin/alluxio-start.sh local 如果希望启动worker，则在配置文件workers中配置所有worker的hostname或ip，回车分割1./bin/alluxio-start.sh all 恭喜！Alluxio已经启动并运行了！你可以访问http://localhost:19999查看Alluxio master的运行状态，访问http://localhost:30000查看Alluxio worker的运行状态。 使用Alluxio Shell 列出文件 1./bin/alluxio fs ls / 上传文件 1./bin/alluxio fs copyFromLocal LICENSE /LICENSE 查看文件 1./bin/alluxio fs cat /LICENSE 关闭1./bin/alluxio-stop.sh all Alluxio后端存储（HDFS） 修改配置文件./conf/alluxio-env.sh 1234ALLUXIO_MASTER_HOSTNAME=$&#123;ALLUXIO_MASTER_HOSTNAME:-&quot;BJYFF3-Basketball-170132&quot;&#125;ALLUXIO_WORKER_MEMORY_SIZE=$&#123;ALLUXIO_WORKER_MEMORY_SIZE:-&quot;85688MB&quot;&#125;ALLUXIO_RAM_FOLDER=$&#123;ALLUXIO_RAM_FOLDER:-&quot;/mnt/ramdisk&quot;&#125;ALLUXIO_UNDERFS_ADDRESS=hdfs://ns2/user/maobaolong/mbl 修改配置文件./conf/alluxio-c 1alluxio.underfs.hdfs.configuration=/home/maobaolong/hadoop_conf/hdfs-site.xml 所有配置1.3版本所有配置 mountbin/alluxio fs mount -readonly /test /software/temp/test/ alluxio使用非root用户启动集群的问题分析mount -t ramfs -o size=100G ramfs /home/appadmin/ramdiskchown appadmin:appadmin /home/appadmin/ramdiskalluxio-start all NoMount mvn installmvn clean install -Dhadoop.version=2.7.1 -Pyarn,spark -DskipTests -Dfindbugs.skip -Dmaven.javadoc.skip -Dcheckstyle.skip]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Linux下文件类型及表示颜色]]></title>
      <url>%2Fgithub_blog%2F2016%2F12%2F01%2F%E6%8A%80%E6%9C%AF%E5%AD%A6%E4%B9%A0%2Flinux%2FLinux%E4%B8%8B%E6%96%87%E4%BB%B6%E7%B1%BB%E5%9E%8B%E5%8F%8A%E8%A1%A8%E7%A4%BA%E9%A2%9C%E8%89%B2%2F</url>
      <content type="text"><![CDATA[Linux下文件类型及表示颜色: 白色：普通文件 (用-表示) n 红色：压缩文件 n 蓝色：目录文件 (用d表示) n 青蓝色：链接文件 (用l表示) n 黄色：设备文件(/dev目录下)(用b或c表示) b表示的是物理设备;c表示的是字符终端设备. n 青绿色：可执行文件(/bin、/sbin目录下) n 粉红色：图片文件或是socket文件(用s表示) n 青黄色：管道文件 (用p表示) Linux下用字符表示的文件类型 -：普通文件 d：目录文件 l：链接文件 b：块设备文件 c：字符设备文件 p：管道文件 Linux文件系统配置文件 /proc—–内核提供的一个接口，主要用来存储系统统计信息; /etc/mtab——–随着/proc/mount的变化而变化，文件系统的安装和卸载都会在这个文件中反映出来; /etc/fstab——-列出当前系统在启动时自动安装的所有文件系统，也可以使用mount -a 这个命令来手动的安 装这个文件中列出的所有文件系统;另外也可以通过修改这个配置文件，使系统在启动时自动安装我们所需要 的其他的文件系统; /etc/mtools.conf———dos文件系统上的操作的配置文件 Linux系统管理配置文件 /etc/group———-列出有效的组名称以及组中的用户信息; /etc/passwd———帐号的密码文件; 帐号—-密码——用户号(UID)—–用户组号(GID)—-所属组—–用户主目录—用户所使用的shell类型 /etc/shadow——–包含加密后的帐号信息; /etc/shells——-包含系统的可以使用的shell的列表; /etc/motd———每日的信息，root管理员向系统中所有用户传达信息时使用 Linux系统命令配置文件 /etc/lilo.conf 包含系统的缺省引导命令行参数，还有启动时使用的不同映象。您在 LILO 引导提示的时候按 Tab 键就可以看到这个列表。 /etc/logrotate.conf 维护 /var/log 目录中的日志文件。 /etc/identd.conf identd是一个超级服务器，这个文件对于的是它的配置文件。 /etc/ld.so.conf “动态链接程序”(Dynamic Linker)的配置。 /etc/inittab 按年代来讲，这是 UNIX 中第一个配置文件。在一台 UNIX 机器打开之后启动的第一个程序是 init，它知道该启动什么，这是由于 inittab 的存在。在运行级别改变时，init 读取 inittab，然后控制主进程的启动 Linux主机配置文件 /etc/host.conf———告诉域名服务器如何查找主机名 /etc/hosts———网络中已发现的主机的名称列表，用于解析主机名 /etc/sysconfig/network 主机名和网关的信息 文件 Linux连网配置文件 /etc/gated.conf gated 的配置。只能被 gated 守护进程所使用。 /etc/networks 列举从机器所连接的网络可以访问的网络名和网络地址。通过路由命令使用。允许使用网络 名称。 /etc/protocols 列举当前可用的协议。 /etc/resolv.conf 在程序请求“解析”一个 IP 地址时告诉内核应该查询哪个名称服务器。 /etc/rpc 包含 RPC 指令/规则，这些指令/规则可以在 NFS 调用、远程文件系统安装等中使用。 /etc/exports 要导出的文件系统(NFS)和对它的权限。 /etc/services 将网络服务名转换为端口号/协议。由 inetd、telnet、tcpdump 和一些其它程序读取。有一些C访问例程。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[元宝]]></title>
      <url>%2Fgithub_blog%2F2016%2F11%2F25%2F%E8%82%B2%E5%84%BF%E7%BB%8F%2F%E5%85%83%E5%AE%9D%2F</url>
      <content type="text"><![CDATA[出生信息日期: 2016-4-30 12:03重量: 3770g 3580g 3620g 3670g身长: 52cm 会翻身3个月 会坐日期: 2016-11-5 六个月 出牙日期:2016-11-4 六个月 会爬期待中 第一次挨摔]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[树莓派上ownCloud的安装]]></title>
      <url>%2Fgithub_blog%2F2016%2F11%2F25%2F%E6%8A%80%E6%9C%AF%E5%AD%A6%E4%B9%A0%2F%E6%A0%91%E8%8E%93%E6%B4%BE%2FownCloud%E5%AE%89%E8%A3%85%2F</url>
      <content type="text"><![CDATA[树莓派上ownCloud的安装12sudo apt-get install apache2 php5 php5-gd php-xml-parser php5-intl php5-sqlite php5-mysql smbclient curl libcurl3 php5-curl mysql-server 安装apache1sudo apt-get install apache2 安装php安装mysql安装owncloud12$ tar xjf owncloud-4.5.6.tar.bz2$ cp -r -v owncloud/ /var/www/owncloud/ 安装ownCloud客户端sudo apt-get install owncloud-client /etc/init.d/apache2 restart]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[jquery中attr和prop的区别（转）]]></title>
      <url>%2Fgithub_blog%2F2016%2F11%2F24%2F%E6%8A%80%E6%9C%AF%E5%AD%A6%E4%B9%A0%2Fweb%2Fjquery%E4%B8%ADattr%E5%92%8Cprop%E7%9A%84%E5%8C%BA%E5%88%AB%2F</url>
      <content type="text"><![CDATA[jquery中attr和prop的区别转自〖芈老头〗的技术空间在高版本的jquery引入prop方法后，什么时候该用prop？什么时候用attr？它们两个之间有什么区别？这些问题就出现了。 关于它们两个的区别，网上的答案很多。这里谈谈我的心得，我的心得很简单： 对于HTML元素本身就带有的固有属性，在处理时，使用prop方法。 对于HTML元素我们自己自定义的DOM属性，在处理时，使用attr方法。 上面的描述也许有点模糊，举几个例子就知道了。 这个例子里&lt;a&gt;元素的DOM属性有href、target和class，这些属性就是&lt;a&gt;元素本身就带有的属性，也是W3C标准里就包含有这几个属性，或者说在IDE里能够智能提示出的属性，这些就叫做固有属性。处理这些属性时，建议使用prop方法。 1&lt;a href=&quot;#&quot; id=&quot;link1&quot; action=&quot;delete&quot;&gt;删除&lt;/a&gt; 这个例子里&lt;a&gt;元素的DOM属性有“href、id和action”，很明显，前两个是固有属性，而后面一个“action”属性是我们自己自定义上去的，&lt;a&gt;元素本身是没有这个属性的。这种就是自定义的DOM属性。处理这些属性时，建议使用attr方法。使用prop方法取值和设置属性值时，都会返回undefined值。 1&lt;a href=&quot;http://www.baidu.com&quot; target=&quot;_self&quot; class=&quot;btn&quot;&gt;百度&lt;/a&gt; 再举一个例子： 12&lt;input id=&quot;chk1&quot; type=&quot;checkbox&quot; /&gt;是否可见&lt;input id=&quot;chk2&quot; type=&quot;checkbox&quot; checked=&quot;checked&quot; /&gt;是否可见 像checkbox，radio和select这样的元素，选中属性对应“checked”和“selected”，这些也属于固有属性，因此需要使用prop方法去操作才能获得正确的结果。 12$(&quot;#chk1&quot;).prop(&quot;checked&quot;) == false$(&quot;#chk2&quot;).prop(&quot;checked&quot;) == true 如果上面使用attr方法，则会出现： 12$(&quot;#chk1&quot;).attr(&quot;checked&quot;) == undefined$(&quot;#chk2&quot;).attr(&quot;checked&quot;) == &quot;checked&quot; 全文完。 以下是官方建议attr(),prop()的使用： Attribute/Property .attr() .prop() accesskey √ align √ async √ √ autofocus √ √ checked √ √ class √ contenteditable √ draggable √ href √ id √ label √ location ( i.e. window.location ) √ √ multiple √ √ readOnly √ √ rel √ selected √ √ src √ tabindex √ title √ type √ width ( if needed over .width() ) √ 转自myloveattribute和property都可以翻译为属性，为了以示区别，通常把这两个单词翻译为属性与特性。 1&lt;div id=&quot;test&quot;&gt;Click Here&lt;/div&gt; 上面这段HTML语句中有三个节点，分别是Element “div”、attribute “id”、Text “click here”，我们最常见的attribute正式指的attribute类型节点，在JavaScript有专门处理attribute的函数 .getAttribute(name) / setAttribute(name,value)。当然attribute不只是我们能够在HTML文档上看到的这几个，我们可以自定义attributed加到DOM节点中 123456&lt;div id=&quot;test&quot;&gt;123&lt;/div&gt; &lt;script type=&quot;text/javascript&quot;&gt; var t=document.getElementById(&apos;test&apos;); t.setAttribute(&apos;class&apos;,&apos;active&apos;); t.setAttribute(&apos;customizedAttr&apos;,&apos;customized&apos;); &lt;/script&gt; 这样可以div被修改为 1&lt;div id=&quot;test&quot; class=&quot;active&quot; customizedattr=&quot;customized&quot;&gt;123&lt;/div&gt; 通过方法 setAttribute设置的attribute最终都会反映到元素的attribute类型的节点中 property是DOM对象的字段，跟我们平常使用的一些对象一样，包含很多字段，这些字段就是property，取值或者设置值和普通字段一样通过”对象.字段“的方式。 看起来attribute和property应该没有什么关系才对，怎么会。。。attribute和property容易混倄是因为很多attribute节点还有一个相对应的property属性，比如上面div的”id“ attribute 同样可以用t.id取到（实际上绝大部分人都是这样获取的），通过property更改id后，用getAttibute获取的id是更新后的id。 12t.id=&apos;test1&apos;;console.log(t.getAttribute(&apos;id&apos;));//test1 同样我们也可以自定义property 1t.customizedProp=&apos;customized prop&apos;; ==区别== 于build-in属性，attribute和property共享数据，attribute更改了会对property造成影响，反之亦然，但是两者的自定义属性是独立的数据，即使name一样，也互不影响，看起来是下面这张图，但是IE6、7没有作区分，依然共享自定义属性数据 并不是所有的attribute与对应的property名字都一致，比如刚才使用的attribute 的class属性，使用property操作的时候应该是这样className 1&lt;input id=&quot;test3&quot; type=&quot;checkbox&quot;/&gt; 1234567891011var t=document.getElementById(&apos;test3&apos;); console.log(t.getAttribute(&apos;checked&apos;));//null console.log(t.checked);//false; t.setAttribute(&apos;checked&apos;,&apos;checked&apos;); console.log(t.getAttribute(&apos;checked&apos;));//checked console.log(t.checked);//true t.checked=false; console.log(t.getAttribute(&apos;checked&apos;));//checked console.log(t.checked);//false 对于一些和路径相关的属性，两者取得值也不尽相同，但是同样attribute取得是字面量，property取得是计算后的完整路径 1&lt;a id=&quot;test4&quot; href=&quot;#&quot;&gt;Click&lt;/a&gt; 123var t=document.getElementById(&apos;test4&apos;); console.log(t.getAttribute(&apos;href&apos;));//# console.log(t.href);//file:///C:/Users/bsun/Desktop/ss/anonymous.html# 关于浏览器（IE）造成的兼容性问题可以看看IE 混淆了 DOM 对象属性（property）及 HTML 标签属性（attribute），造成了对 setAttribute、getAttribute 的不正确实现 ==attr和prop==相信看完上面内容，大家就明白为什么jQuery要添加prop方法了，在jQuery API中也有专门解释Attributes VS. Properties在一些特殊的情况下，attributes和properties的区别非常大。在jQuery1.6之前，.attr()方法在获取一些attributes的时候使用了property值，这样会导致一些不一致的行为。在jQuery1.6中，.prop()方法提供了一中明确的获取property值得方式，这样.attr()方法仅返回attributes。 比如，selectedIndex, tagName, nodeName, nodeType, ownerDocument, defaultChecked, 和defaultSelected应该使用.prop()方法获取/设置值。 在jQuery1.6之前这些不属于attribute的property需要用.attr()方法获取。这几个并没有相应的attibute，只有property。 关于布尔类型 attributes，比如一个这样的HTML标签，它在JavaScript中变量名为elem 1&lt;input type=&quot;checkbox&quot; checked=&quot;checked&quot; /&gt; elem.checked true (Boolean) Will change with checkbox state $( elem ).prop( “checked” ) true (Boolean) Will change with checkbox state elem.getAttribute( “checked” ) “checked” (String) Initial state of the checkbox; does not change $( elem ).attr( “checked” ) (1.6) “checked” (String) Initial state of the checkbox; does not change $( elem ).attr( “checked” ) (1.6.1+) “checked” (String) Will change with checkbox state $( elem ).attr( “checked” ) (pre-1.6) true (Boolean) Changed with checkbox state 根据W3C forms specification，checked属性是一个布尔值，这就意味着只要checked属性在HTML中表现出来了，那么相应的property就应该是true，即使checked没有值，这点儿对其它布尔类型的属性一样适用。 然而关于checked 属性需要记住的最重要的一点是：它和checked property并不是一致的。实际上这个attribute和defaultChecked property一致，而且只应该用来设置checkbox的初始值。checked attribute并不随着checkedbox的状态而改变，但是checked property却跟着变。因此浏览器兼容的判断checkebox是否被选中应该使用property 123if ( elem.checked )if ( $( elem ).prop( &quot;checked&quot; ) )if ( $( elem ).is( &quot;:checked&quot; ) ) 这对其它一些类似于selected、value这样的动态attribute也适用。 在IE9之前版本中，如果property没有在DOM元素被移除之前删除，使用.prop()方法设置DOM元素property（简单类型除外：number、string、boolean）的值会导致内存泄露。为了安全的设置DOM对象的值，避免内存泄露，可以使用.data()方法。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[idea]]></title>
      <url>%2Fgithub_blog%2F2016%2F11%2F21%2F%E5%B7%A5%E5%85%B7%E4%BD%BF%E7%94%A8%2Fidea%2F</url>
      <content type="text"><![CDATA[maven helpermaven依赖冲突解决利器]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[maven]]></title>
      <url>%2Fgithub_blog%2F2016%2F11%2F16%2F%E5%B7%A5%E5%85%B7%E4%BD%BF%E7%94%A8%2Fmaven%2F</url>
      <content type="text"><![CDATA[maven 安装本地库mvn install:install-file -DgroupId=com.facebook.presto -DartifactId=presto-jdbc -Dversion=0.132-SNAPSHOT -Dpackaging=jar -Dfile=presto-jdbc-0.132-SNAPSHOT.jar 打包jar依赖包独立存在12345678910111213141516pom中加入&lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-jar-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;archive&gt; &lt;manifest&gt; &lt;addClasspath&gt;true&lt;/addClasspath&gt; &lt;mainClass&gt;youmainclasspath&lt;/mainClass&gt; &lt;/manifest&gt; &lt;/archive&gt; &lt;/configuration&gt; &lt;/plugin&gt;执行 mvn dependency:copy-dependencies -DoutputDirectory=lib package然后把lib里的所有jar放到你工程的jar包所在的目录运行java -jar youjar.jar Maven中-DskipTests和-Dmaven.test.skip=true的区别在使用mvn package进行编译、打包时，Maven会执行src/test/java中的JUnit测试用例，有时为了跳过测试，会使用参数-DskipTests和-Dmaven.test.skip=true，这两个参数的主要区别是： -DskipTests，不执行测试用例，但编译测试用例类生成相应的class文件至target/test-classes下。 -Dmaven.test.skip=true，不执行测试用例，也不编译测试用例类。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[velocity]]></title>
      <url>%2Fgithub_blog%2F2016%2F11%2F09%2F%E6%8A%80%E6%9C%AF%E5%AD%A6%E4%B9%A0%2Fvelocity%2F</url>
      <content type="text"><![CDATA[JAVA中的map传到vm中12345678910One option along the lines of what you already have should be to add the attributes to the model as a map. So in javamap = new HashMap(); map.put(&quot;id&quot;, &quot;solikang&quot;)map.put(&quot;pwd&quot;, &quot;1234&quot;)map.put(&quot;email&quot;, &quot;something@example.com&quot;);model.addAttribute(&quot;data&quot;, map);Then in velocity#foreach ($key in $data.keySet()) &lt;input type=&quot;hidden&quot; name=&quot;$key&quot; value=&quot;$data.get($key)&quot;&gt;#end]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[jenkins]]></title>
      <url>%2Fgithub_blog%2F2016%2F11%2F09%2F%E5%B7%A5%E5%85%B7%E4%BD%BF%E7%94%A8%2Fjenkins%2F</url>
      <content type="text"><![CDATA[jenkins[TOC] 启动jenkins指定端口java -jar jenkins.war –httpPort=9010 后台启动的方法 nohup command &gt; myout.file 2&gt;&amp;1 &amp;1kill `ps -ef | grep [j]enkins.war | awk &apos;&#123; print $2 &#125;&apos;` jenkins中通过execute shell启动的进程会被杀死的问题[摘要：正在jenkins中设置装备摆设主动更新安排项目时，若是采用用execute shell启动/封闭tomcat，会发明能够举行封闭tomcat，然则没法启动tomcat，固然构建会表现履行乐成，然则检察过程，tomcat是出有启动的]在jenkins中配置自动更新部署项目时，如果采取用execute shell启动/关闭tomcat，会发现可以进行关闭tomcat，但是无法启动tomcat，虽然构建会显示执行成功，但是查看进程，tomcat是没有启动的。这是因为Jenkins默认会在Build结束后Kill掉所有的衍生进程。需要进行以下配置，才能避免此类情况发生: 重设环境变量build_id在execute shell输入框中加入BUILD_ID=DONTKILLME,即可防止jenkins杀死启动的tomcat进程 在启动jenkins 的时候禁止jenkins杀死衍生进程 修改/etc/sysconfig/jenkins配置，在JENKINS_JAVA_OPTIONS中加入-Dhudson.util.ProcessTree.disable=true。需要重启jenkins生效 此方法配置一次后，所有的job都无需设置BUILD_ID，就能够防止jenkins杀死启动的tomcat进程]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[zookeeper]]></title>
      <url>%2Fgithub_blog%2F2016%2F11%2F09%2F%E6%8A%80%E6%9C%AF%E5%AD%A6%E4%B9%A0%2Fzookeeper%2F</url>
      <content type="text"><![CDATA[zkCli.sh -server IP:port ls(查看当前节点数据),ls2(查看当前节点数据并能看到更新次数等数据) ,create(创建一个节点) ,get(得到一个节点，包含数据和更新次数等数据),set(修改节点)delete(删除一个节点) 四字命令，nc 服务器地址 端口号nc 192.168.193.84 2181 ZooKeeper 四字命令 功能描述 conf 输出相关服务配置的详细信息。 cons 列出所有连接到服务器的客户端的完全的连接 / 会话的详细信息。包括“接受 / 发送”的包数量、会话 id 、操作延迟、最后的操作执行等等信息。 dump 列出未经处理的会话和临时节点。 envi 输出关于服务环境的详细信息（区别于 conf 命令）。 reqs 列出未经处理的请求 ruok 测试服务是否处于正确状态。如果确实如此，那么服务返回“ imok”，否则不做任何相应。 stat 输出关于性能和连接的客户端的列表。 wchs 列出服务器 watch 的详细信息。 wchc 通过 session 列出服务器 watch 的详细信息，它的输出是一个与watch 相关的会话的列表。 wchp 通过路径列出服务器 watch 的详细信息。它输出一个与 session 相关的路径。 mntr 显示zk信息 获取当前zk服务器的serverIdecho conf|nc 192.168.193.83 2181 获取当前zk服务器的角色，如果为leader，则可以获得follower个数echo mntr|nc 192.168.193.85 2181]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[正则表达式]]></title>
      <url>%2Fgithub_blog%2F2016%2F11%2F09%2F%E6%8A%80%E6%9C%AF%E5%AD%A6%E4%B9%A0%2F%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%2F</url>
      <content type="text"><![CDATA[常见用法(?: pattern)是非捕获型括号 匹配pattern，但不捕获匹配结果。(pattern )是捕获型括号。 匹配pattern，匹配pattern并捕获结果,自动获取组号(? pattern ) 匹配pattern， 匹配pattern并捕获结果，设置name为组名 使用小括号指定一个子表达式后，匹配这个子表达式的文本(也就是此分组捕获的内容)可以在表达式或其它程序中作进一步的处理。默认情况下，每个捕获组会自动拥有一个组号，规则是：从左向右，以分组的左括号为标志，第一个出现的分组的组号为1，第二个为2，以此类推。 如果正则表达式中同时存在普通捕获组和命名捕获组，那么捕获组的编号就要特别注意，编号的规则是先对普通捕获组进行编号，再对命名捕获组进行编号。 为了避免括号太多使编号混乱，也为了避免无用的捕获提高效率，在不需要捕获只需要指定分组的地方就可以使用非捕获型括号。问题里的非捕获型括号就是为此使用的。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[java 远程调试]]></title>
      <url>%2Fgithub_blog%2F2016%2F11%2F09%2F%E6%8A%80%E6%9C%AF%E5%AD%A6%E4%B9%A0%2Fjava%2Fjava%2F</url>
      <content type="text"><![CDATA[远程调试1java -Xdebug -Xnoagent -Djava.compiler=NONE -Xrunjdwp:transport=dt_socket,server=y,suspend=y,address=2345 Main 运行jar中的包含main函数的类-cp app.jar a.b.C 1//其中C是类位于a.b包,C类中包含main]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[git]]></title>
      <url>%2Fgithub_blog%2F2016%2F11%2F09%2F%E5%B7%A5%E5%85%B7%E4%BD%BF%E7%94%A8%2Fgit%2F</url>
      <content type="text"><![CDATA[git push origin master报错fatal: could not read Username for ‘https://github.com‘: No such file or directo原因使用https方式的时候 在git remote add origin 的https url 里面没有用户名和密码修改为如下：git remote add origin https://{username}:{password}@github.com/{username}/project.githttps://github.com/kemayo/sublime-text-git/issues/176或者直接修改 .git/config 隐藏文件 为git remote add origin https://{username}:{password}@github.com/{username}/project.git 格式 显示当前分支git branch 显示远程信息git remote -v 强制回退到master分支取回远程主机某个分支的更新，再与本地的指定分支合并git pull &lt;远程主机名&gt; &lt;远程分支名&gt;:&lt;本地分支名&gt;git pull origin master:master -f 显示git状态git status git branch * master 将master分支合并到当前分支git merge master 将远程master的修改合并到本地mbl分支。git pull origin master:master -fgit add . git commit -m “test”git pull origin master:master -fgit branch * mastergit checkout mblgit pullgit merge master git push 取消commit 和 pullgit reset –hard git push origin HEAD –force git 更换仓库 从原地址克隆一份裸版本库，比如原本托管于 GitHubgit clone –bare git://github.com/username/project.git 然后到新的 Git 服务器上创建一个新项目，比如 GitCafe。 以镜像推送的方式上传代码到 GitCafe 服务器上。 12cd project.gitgit push --mirror git@gitcafe.com/username/newproject.git 先查看remote的名字 1git branch -r 假设你的remote是origin，用git remote set_url 更换地址 1git remote set-url origin remote_git_address 提交代码1git commit -am &quot;提交说明&quot; 追踪远端更新 为了将远程的Alluxio源码改动更新到你本地的副本中，你需要创建一个指向远程Alluxio源代码库的源。在刚拷贝的副本的目录下，运行： 1git remote add upstream https://github.com/Alluxio/alluxio.git 显示所有分之，并比较本地和远端分之版本 1git branch -av 把远端的分支抓取过来 1git fetch 切换到分支 1git checkout --track remotes/upstream/branch-1.4 revert file,such as pom.xml 12git checkout -- pom.xmlgit push origin branch-1.4 merge master branch 12345git checkout mastergit merge upstream/mastergit branch -avgit status git push create a sub branch of an assigned branch 12345#切换到分支git checkout branch1#基于该分支创建子分支git checkout -b branch2_based_on_b1 branch1 为推送当前分支并建立与远程上游的跟踪 1git push --set-upstream origin mbl-baseon-JDAlluxio-1.3.0]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[CENTOS笔记]]></title>
      <url>%2Fgithub_blog%2F2016%2F11%2F09%2F%E6%8A%80%E6%9C%AF%E5%AD%A6%E4%B9%A0%2Flinux%2Fcentos%2F</url>
      <content type="text"><![CDATA[CENTOS笔记[TOC] ##连接无线网 ip addr找到自己的无线网接口 （ps:本人的是wlp5s0） ip link set wlp5s0 up打开无线网的驱动 ip link show wlp5s0查看该网络接口的状态 连接无线网wpa_supplicant -B -i wlp5s0 -c &lt;(wpa_passphrase “ssid” “psk”) (连接无线网ssid，密码psk) dhcp分配ipdhclient wlp5s0(为wlp5s0分配ip地址) 软件源下载源wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repowget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.163.com/.help/CentOS7-Base-163.repo wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.sohu.com/help/CentOS-Base-sohu.repowget -O /etc/yum.repos.d/CentOS-Base.repo http://centos.ustc.edu.cn/CentOS-Base.repo 安装源yum clean allyum makecache ssh修改端口号step1 修改/etc/ssh/sshd_configvi /etc/ssh/sshd_config12#Port 22 //这行去掉#号Port 20000 //下面添加这一行 step2 修改SELinuxyum -y install policycoreutils-python 使用以下命令查看当前SElinux 允许的ssh端口：semanage port -l | grep ssh 添加20000端口到 SELinuxsemanage port -a -t ssh_port_t -p tcp 20000 然后确认一下是否添加进去semanage port -l | grep ssh如果成功会输出ssh_port_t tcp 20000, 22 step3 重启sshsystemctl restart sshd.service]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[linux命令]]></title>
      <url>%2Fgithub_blog%2F2016%2F11%2F09%2F%E6%8A%80%E6%9C%AF%E5%AD%A6%E4%B9%A0%2Flinux%2Flinux%20%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%2F</url>
      <content type="text"><![CDATA[#linux 常用命令 * history |grep scp * tail -f log/UGDAP.log * 只显示文件名： ls -l | grep ^[^d] | awk ‘{print $8}’只显示文件夹名：ls -l |grep ^d | awk ‘{print $8}’ 或者是 ls -d */ 恢复rm删除的文件显示所删除的文件所在的分区df -T /home 用debugFS查找被删除文件的inode号sudo debugfsdebugfs&gt;open /dev/sda5debugfs&gt;ls -d /home/mbl/study尖括号中的是inode 恢复inodeextundelete ${dev_describer} –restore-inode ${inode} 如果知道被删除文件的完整的路径，直接恢复extundelete ${deb_describer} –restore-file ${path} shell脚本常用变量$0: shell或shell脚本的名字$*:以一对双引号给出参数列表$@:将各个参数分别加双引号返回$#:参数的个数$_:代表上一个命令的最后一个参数$$:代表所在命令的PID$!:代表最后执行的后台命令的PID$?:代表上一个命令执行后的退出状态 curl curl -x 172.22.91.78:80 http://172.16.172.95:19888/ws/v1/history/mapreduce/jobs/job_1470405196301_64273|python -m json.tool&gt;job_1470405196301_64273.json 显示当前版本cat /proc/versionuname -acat /etc/release 显示iphostname -iifconfig -a|grep inet|grep -v 127.0.0.1|grep -v inet6 | awk ‘{print $2}’ | tr -d “addr:”ifconfig enp0s25|grep inet|grep -v 127.0.0.1|grep -v inet6 | awk ‘{print $2}’ | tr -d “addr:” 测试端口是否通telnet 172.22.91.34 8087 查看端口是否被占用netstat -tunlp |grep 80lsof -i 80 /bin/bash^M: 解释器错误: 没有那个文件或目录sed -i ‘s/\r$//‘ check_tool.sh 后台启动进程，重定向输出到文件nohup command &gt; myout.file 2&gt;&amp;1 &amp; 杀进程ps -ef | grep tomcat | awk ‘{print $2}’ | xargs kill -9或kill ps -ef | grep [j]enkins.war | awk &#39;{ print $2 }&#39;虽然提示没有找到进程pid，但已经杀掉了 开机自动挂载分区用blkid列出分区uuid和typesudo blkid接下来修改自动挂载的配置文件：sudo vim /etc/fstab增加一行UUID=11263962-9715-473f-9421-0b604e895aaa /data ext4 defaults 0 1 zip解压中文乱码ubuntu下 unzip -O CP936 xxx.zip -d exdir 权限home目录不能有其它用户写权限/root .ssh 只能是 700 linux权限777 rwxrwxrwx （所有者，本组用户，其它用户）rwx=读，写，执行 ssh-copy-id设置root密码sudo passwd root 在任务栏显示网速sudo add-apt-repository ppa:nilarimogard/webupd8sudo apt-get updatesudo apt-get install indicator-netspeed 设置显示桌面快捷键sudo apt-get install compizconfig-settings-managerccsm KWPlayer 酷我音乐盒Iptux — 局域网聊天工具(飞鸽Linux版)sudo apt-get install iptux System Load Indicator ( 系统状态指示器）sudo add-apt-repository ppa:indicator-multiload/stable-dailysudo apt-get updatesudo apt-get install indicator-multiload XBMC（媒体中心）XBMC（媒体中心）sudo add-apt-repository ppa:team-xbmc/ppasudo apt-get updatesudo apt-get install xbmc VMware Workstation安装方法（包含下载、安装、激活、序列号）http://www.kashu.org/1024.html wiresharkhttp://ppa.launchpad.net/wireshark-dev/stable/ubuntu/pool/main/w/wireshark/ppa:wireshark-dev/stable .tar.gz 格式解压为 tar -zxvf xx.tar.gz -C targetDir.tar.bz2 格式解压为 tar -jxvf xx.tar.bz2 查看linux版本rpm -qa|grep kernel 中文Linux 常用的locale是zh_CN.gb2312，zh_CN.gbk，zh_CN.gb18030 和 zh_CN.UTF-8 。通过如下命令可以查询系统的locale：echo $LANG 挂载u盘123456fdisk -l mkdir /mnt/usbmount命令格式：mount [-参数] [设备名称] [挂载点] [其他参数]mount /dev/sdb1 /mnt/usbumount /dev/sdb1 改变用户组和用户123456789基本语法：chown [-R] 账号名称 文件或目录chown [-R] 账号名称:用户组名称 文件或目录参数：-R : 进行递归( recursive )的持续更改，即连同子目录下的所有文件、目录都更新成为这个用户组。常常用在更改某一目录的情况。示例1：[root@localhost home]# touch testfile //由 root 用户创建文件[root@localhost home]# ls testfile –l 查看文件夹下容量du -ah –max-depth=1 配置ssh 超时空闲时间服务器配置:123/etc/profile 中的配置，增加一个参数TMOUT=6000 //100分钟，应该够用了echo &quot;TMOUT=6000 &quot; &gt;&gt;/etc/profilesource /etc/profile //立即生效 客户端配置:方法很简单，只需在客户端电脑上编辑（需要root权限）/etc/ssh/ssh_config，并添加如下一行：ServerAliveInterval 60 服务器端设置: 如果有相应的权限，也可以在服务器端设置，即编辑/etc/ssh/sshd_config，并添加：ClientAliveInterval 60 重启SSH服务器后该项设置会生效。每一个连接到此服务器上的客户端都会受其影响。应注意启用该功能后，安全性会有一定下降（比如忘记登出时……） Linux常见问题解答–如何修复”tar：由于前一个错误导致于失败状态中退出”Exiting with failure status due to previous errors去掉v，只看错误流 百度网盘公开链接wget下载wget -c –referer=公开链接地址 -O 输出文件名 “直接下载地址” ，其中-c表示断点续传wget -c –referer=http://pan.baidu.com/s/1pL0IUxH -O a.zip “http://61.179.228.93/d1.baidupcs.com/file/4b43140bd6212b333237b391961932a4?bkt=p3-0000eea78a1d47d0402b131c2736fe70a488&amp;xcode=c0a39d5fa7dcff84c1a1bca47e82ddfb123eeb8f4d2e9e54ded0b7c77404c736&amp;fid=50867796-250528-751846568268583&amp;time=1481855378&amp;sign=FDTAXGERLBH-DCb740ccc5511e5e8fedcff06b081203-mq8GWRwB7zY3FSpQOglOpVoSn8I%3D&amp;to=lc&amp;fm=Qin,B,U,nc&amp;sta_dx=137584648&amp;sta_cs=2496&amp;sta_ft=7z&amp;sta_ct=7&amp;sta_mt=7&amp;fm2=Qingdao,B,U,nc&amp;newver=1&amp;newfm=1&amp;secfm=1&amp;flow_ver=3&amp;pkey=14005e8f94567db20cb9f1c95efbd7a8a7b7c50dcb1a000008336008&amp;sl=75956300&amp;expires=8h&amp;rt=sh&amp;r=739923821&amp;mlogid=8127629174281954396&amp;vuk=-&amp;vbdid=2201694974&amp;fin=FIFA.2002.Green.Edition-ALI213.7z&amp;fn=FIFA.2002.Green.Edition-ALI213.7z&amp;slt=pm&amp;uta=0&amp;rtype=1&amp;iv=0&amp;isw=0&amp;dp-logid=8127629174281954396&amp;dp-callid=0.1.1&amp;csl=600&amp;csign=RJ%2BYoZ6FqCL1OLeGHSbtuImu3ys%3D&amp;wshc_tag=0&amp;wsts_tag=58535192&amp;wsid_tag=6fccf309&amp;wsiphost=ipdbm“ history:n copy line n to current input line]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[shell脚本]]></title>
      <url>%2Fgithub_blog%2F2016%2F11%2F09%2F%E6%8A%80%E6%9C%AF%E5%AD%A6%E4%B9%A0%2Flinux%2Fshell%E8%84%9A%E6%9C%AC%2F</url>
      <content type="text"><![CDATA[cd dirname $0]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[ubuntu]]></title>
      <url>%2Fgithub_blog%2F2016%2F11%2F09%2F%E6%8A%80%E6%9C%AF%E5%AD%A6%E4%B9%A0%2Flinux%2Fubuntu%2F</url>
      <content type="text"><![CDATA[删除无用软件 删除libreoffice 1sudo apt-get remove libreoffice-common 删除Amazon的链接 1sudo apt-get remove unity-webapps-common 删掉基本不用的自带软件 12sudo apt-get remove thunderbird totem rhythmbox empathy brasero simple-scan gnome-mahjongg aisleriot gnome-mines cheese transmission-common gnome-orca webbrowser-app gnome-sudoku landscape-client-ui-installsudo apt-get remove onboard deja-dup 常用软件 名称 说明 ssh 客户端 openssh-server 服务端 mysql-server mysql-client wine gdebi virtualbox 虚拟机 chrome sougou wps idea hadoop 中文字体12345678sudo apt-get install ttf-mscorefonts-installer #微软字体 sudo apt-get install xfonts-wqy #文泉驿-点阵宋体 cd ~ wget http://www.stchman.com/tools/MS_fonts/tahoma.zip #Tahoma 字体 sudo unzip -d /usr/share/fonts/truetype/msttcorefonts ~/tahoma.zip sudo fc-cache -f -v rm -f ~/tahoma.zip sudo fc-cache -f -s -v #刷新字体缓存 解压配置常见问题root下无法输入中文/etc/profile中 export XMODIFIERS=@im=fcitx GTK_IM_MODULE=xim WPS下搜狗输入法不能输入中文原因：环境变量未正确设置$ vi /usr/bin/wps在第一行 #!/bin/bash 下添加：export XMODIFIERS=”@im=fcitx”export QT_IM_MODULE=”fcitx” ppt、excel部分和word一样的方法添加环境变量，只是编辑的文件各不同：$ vi /usr/bin/wpp$ vi /usr/bin/et idea root无法输入中文在IDEA的bin目录下的idea.sh文件的前面加上：export XMODIFIERS=@im=fcitx export QT_IM_MODULE=fcitx 无法打开系统设置sudo apt-get install unity-control-center Ubuntu上方边栏不显示时间，有三中可能原因及相应的解决方法：1. 原因：系统设置为了不显示时间。 解决方法：右上角小齿轮-&gt;系统设置-&gt;时间和日期-&gt;时钟-&gt;勾选“在菜单栏显示时钟” 2. 原因：显示时间的进程出错了。 3. 解决方法：重新登录，或重启电脑，或使用下述命令： sudo restart lighddm警告：该命令会使所有用户退出登录。 4. 原因：indicator-datetime 被误删了。 解决方法：重新安装indicator-datetime。 首先，在确认indicator-datetime确实被误删之后，使用命令sudo apt-get install indicator-datetime 安装。其次，配置日期时间：sudo dpkg-reconfigure –frontend noninteractive tzdata 。最后，重启unity：sudo killall unity-panel-service 。 设置分辨率 xrandr1sudo xrandr -s 1360x768_60]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[haproxy]]></title>
      <url>%2Fgithub_blog%2F2016%2F11%2F09%2F%E5%B7%A5%E5%85%B7%E4%BD%BF%E7%94%A8%2Fhaproxy%2F</url>
      <content type="text"><![CDATA[编译1uname -a 查看linux版本vim -R README ，查找 ?linux ，N查找下一个，找到linux版本对应targetmake TARGET=linux2628 ubuntu apt-get install haproxy安装即可centos 用yum安装即可yum haproxy -yhaproxy x86_64 1.5.14-3.el7 base 833 k]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[scrt 破解和使用]]></title>
      <url>%2Fgithub_blog%2F2016%2F11%2F09%2F%E5%B7%A5%E5%85%B7%E4%BD%BF%E7%94%A8%2Fscrt%2F</url>
      <content type="text"><![CDATA[scrtlinux下破解12345Name: xiaobo_lCompany:www.boll.meSerial Number:03-61-166978License Key:ABC89D UFDU94 C94CBU 7V17SU ABTUS5 QXX9E5 PF12H6 R62SHCIssue Date:12-22-2013 设置反空闲会话选项 –&gt; 终端 –&gt; 反空闲 –&gt; 发送字符串 可以设置，比如发送 \n 、null或其他信息过去，后面可以设置每隔多少秒发送，比如可以3000秒一次，这样可以保证不会掉线 全局会话设置如果想应用于所有会话的话，选择全局选项-&gt;默认会话-&gt;编辑默认设置.做上述修改修改就可以全局使用了.]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[html]]></title>
      <url>%2Fgithub_blog%2F2016%2F11%2F09%2F%E6%8A%80%E6%9C%AF%E5%AD%A6%E4%B9%A0%2Fweb%2Fhtml%2F</url>
      <content type="text"><![CDATA[事件相应两次的问题12345678910111213141516171819202122232425&lt;html&gt;&lt;head&gt;&lt;meta charset=&quot;utf-8&quot;&gt;&lt;title&gt;菜鸟教程(runoob.com)&lt;/title&gt;&lt;script src=&quot;http://apps.bdimg.com/libs/jquery/2.1.4/jquery.min.js&quot;&gt;&lt;/script&gt;&lt;/head&gt;&lt;body&gt; &lt;label id=&quot;mylabel&quot; &gt; &lt;input type=&quot;checkbox&quot; value=&quot;&quot; level=&quot;$!category.level&quot; data-id=&quot;$!category.id&quot; data-parentId=&quot;$!categoryInfo.id&quot; data-type=&quot;categoryInfoType&quot;&gt;$!category.name&lt;/label&gt;&lt;div id=&quot;test&quot;&gt; &lt;input type=&quot;checkbox&quot; name=&quot;abc&quot; id=&quot;abc&quot;/&gt; &lt;label for=&quot;abc&quot;&gt;3423432432432432&lt;/label&gt;&lt;/div&gt;&lt;script type=&quot;text/javascript&quot;&gt; $(&quot;#test&quot;).click(function(ev) &#123; console.log(ev.target); &#125;); $(&quot;#mylabel&quot;).click(function(event) &#123;console.log(event.target);&#125;);&lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 设置textArea 允许拖动方向1&lt;textarea style=&quot;resize:vertical;&quot;&gt;&lt;/textarea&gt; resize的值，可以为： both vertical horizontal none]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[springMVC]]></title>
      <url>%2Fgithub_blog%2F2016%2F11%2F09%2F%E6%8A%80%E6%9C%AF%E5%AD%A6%E4%B9%A0%2Fweb%2FspringMVC%2F</url>
      <content type="text"><![CDATA[基于注解的Spring AOP的配置和使用AOP是OOP的延续，是Aspect Oriented Programming的缩写，意思是面向切面编程。可以通过预编译方式和运行期动态代理实现在不修改源代码的情况下给程序动态统一添加功能的一种技术。AOP实际是GoF设计模式的延续，设计模式孜孜不倦追求的是调用者和被调用者之间的解耦，AOP可以说也是这种目标的一种实现。 切面（Aspect）：官方的抽象定义为“一个关注点的模块化，这个关注点可能会横切多个对象”，在本例中，“切面”就是类TestAspect所关注的具体行为，例如，AServiceImpl.barA()的调用就是切面TestAspect所关注的行为之一。“切面”在ApplicationContext中来配置。 连接点（Joinpoint） ：程序执行过程中的某一行为，例如，UserService.get的调用或者UserService.delete抛出异常等行为。 通知（Advice） ：“切面”对于某个“连接点”所产生的动作，例如，TestAspect中对com.spring.service包下所有类的方法进行日志记录的动作就是一个Advice。其中，一个“切面”可以包含多个“Advice”，例如ServiceAspect。 切入点（Pointcut） ：匹配连接点的断言，在AOP中通知和一个切入点表达式关联。例如，TestAspect中的所有通知所关注的连接点，都由切入点表达式execution( com.spring.service..*(..))来决定。 目标对象（Target Object） ：被一个或者多个切面所通知的对象。例如，AServcieImpl和BServiceImpl，当然在实际运行时，Spring AOP采用代理实现，实际AOP操作的是TargetObject的代理对象。 AOP代理（AOP Proxy） ：在Spring AOP中有两种代理方式，JDK动态代理和CGLIB代理。默认情况下，TargetObject实现了接口时，则采用JDK动态代理，例如，AServiceImpl；反之，采用CGLIB代理，例如，BServiceImpl。强制使用CGLIB代理需要将 的 proxy-target-class属性设为true。 通知（Advice）类型： 前置通知（Before advice）：在某连接点（JoinPoint）之前执行的通知，但这个通知不能阻止连接点前的执行。ApplicationContext中在里面使用元素进行声明。例如，TestAspect中的doBefore方法。 后置通知（After advice）：当某连接点退出的时候执行的通知（不论是正常返回还是异常退出）。ApplicationContext中在里面使用元素进行声明。例如，ServiceAspect中的returnAfter方法，所以Teser中调用UserService.delete抛出异常时，returnAfter方法仍然执行。 返回后通知（After return advice）：在某连接点正常完成后执行的通知，不包括抛出异常的情况。ApplicationContext中在里面使用元素进行声明。 环绕通知（Around advice）：包围一个连接点的通知，类似Web中Servlet规范中的Filter的doFilter方法。可以在方法的调用前后完成自定义的行为，也可以选择不执行。ApplicationContext中在里面使用元素进行声明。例如，ServiceAspect中的around方法。 抛出异常后通知（After throwing advice）：在方法抛出异常退出时执行的通知。ApplicationContext中在里面使用元素进行声明。例如，ServiceAspect中的returnThrow方法。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[jquery]]></title>
      <url>%2Fgithub_blog%2F2016%2F11%2F09%2F%E6%8A%80%E6%9C%AF%E5%AD%A6%E4%B9%A0%2Fweb%2Fjquery%2F</url>
      <content type="text"><![CDATA[jquery$(“#id”)$(“.样式”)$(“标签名[属性名=属性值][属性名2=属性值2][属性名3!=属性值3]”) $(“input[data-type=group_checkbox]”)$(this)$(#id).find(“input”) 查找后代input元素 $(“#addQueueDiv”).show();$(“#addQueueDiv”).hide(); $(“#addQueueDiv”)[0].style.visibility=”visible”$(“#addQueueDiv”)[0].style.visibility=”hidden” tab切换事件$(document).on(‘shown.bs.tab’, ‘a[data-toggle=”tab”]’, function(e) { console.log(e.target) // activated tab});]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[nginx]]></title>
      <url>%2Fgithub_blog%2F2016%2F11%2F09%2F%E5%B7%A5%E5%85%B7%E4%BD%BF%E7%94%A8%2Fnginx%2F</url>
      <content type="text"><![CDATA[启动nginx 重启nginx -s reload 关闭nginx -s stop 修改端口/etc/nginx/conf/nginx.conf 查看端口占用lsof -i tcp:80lsof -i tcp:8999 检测配置文件是否正确，可以查看配置文件位置sudo nginx -t 查看版本sudo nginx -V 配置文件说明server_namn : 域名;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[playframework]]></title>
      <url>%2Fgithub_blog%2F2016%2F11%2F09%2F%E6%8A%80%E6%9C%AF%E5%AD%A6%E4%B9%A0%2Fweb%2Fplayframework%2F</url>
      <content type="text"><![CDATA[目录结构123456789101112131415161718192021222324252627282930313233343536373839web_app 根目录 | sbt SBT Unix 批处理脚本用于启动sbt-launch.jar | sbt.bat SBT Windows 批处理脚本用于启动sbt-launch.jar | sbt-launch.jar SBT 启动的Java可执行类库|+---app Play Web 应用全部代码所在目录| || +---models 模型代码所在目录| | Message.scala 留言板例程模型代码| || +---controllers 控制器代码所在目录| | Application.scala 默认控制器代码| || \---views 视图（Play Scala HTML模板） 代码所在目录| main.scala.html 主模板文件| index.scala.html 首页模板文件| msgboard.scala.html 留言板例程模板文件|+---conf Play 配置文件所在目录| application.conf 应用配置文件| routes 应用入口路由文件，所有的HTTP请求将通过该文件转发到指定的Scala对象处理|+---logs 日志目录| application.log 应用运行日志|+---project SBT工程文件| build.properties 保存所需的SBT版本信息，通常无需更改| Build.scala 主要的工程配置文件| plugins.sbt 告知SBT本工程所需要的插件以及下载位置|+---public 存储一切直接发送给浏览器的资源文件| || +---images 图像文件，如JPEG、PNG、GIF等| || +---javascripts JavaScript脚本文件| || \---stylesheets CSS样式表文件|\---target 存放编译后的可执行代码和编译时的中间代码 执行play,进入play命令行后，执行:idea with-sources=yes 或者 eclipse with-source=true.生成对应的工程文件，之后，可以用eclipse或idea导入工程；]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[velocity]]></title>
      <url>%2Fgithub_blog%2F2016%2F11%2F09%2F%E6%8A%80%E6%9C%AF%E5%AD%A6%E4%B9%A0%2Fweb%2Fvelocity%2F</url>
      <content type="text"><![CDATA[velocity 设置模板1#set($layout = &quot;/layout/layout2.vm&quot;)]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[seafile]]></title>
      <url>%2Fgithub_blog%2F2016%2F11%2F09%2F%E5%B7%A5%E5%85%B7%E4%BD%BF%E7%94%A8%2Fseafile%2F</url>
      <content type="text"><![CDATA[seafile启动停止服务/opt/seafile/seafile-server-6.0.5/seafile.sh stop/opt/seafile/seafile-server-6.0.5/seahub.sh stop /opt/seafile/seafile-server-6.0.5/seafile.sh start/opt/seafile/seafile-server-6.0.5/seahub.sh start 8123]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[xss攻击]]></title>
      <url>%2Fgithub_blog%2F2016%2F11%2F09%2F%E6%8A%80%E6%9C%AF%E5%AD%A6%E4%B9%A0%2Fweb%2Fxss%E6%94%BB%E5%87%BB_%E8%B7%A8%E5%9F%9F%E6%94%BB%E5%87%BB%2F</url>
      <content type="text"><![CDATA[xss攻击]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[树莓派安装后需要做的几件事]]></title>
      <url>%2Fgithub_blog%2F2016%2F11%2F09%2F%E6%8A%80%E6%9C%AF%E5%AD%A6%E4%B9%A0%2F%E6%A0%91%E8%8E%93%E6%B4%BE%2F%E5%AE%89%E8%A3%85%E5%90%8E%2F</url>
      <content type="text"><![CDATA[安装后ssh登录查看路由器dhcp列表，获取ip，使用scrt登录修改/etc/apt/sources.list12deb http://mirrors.aliyun.com/raspbian/raspbian/ jessie main non-free contrib rpideb-src http://mirrors.aliyun.com/raspbian/raspbian/ jessie main non-free contrib rpi 远程桌面安装远程桌面，ubuntu下需要使用xrdesktop连接 ，比windows远程桌面慢12sudo apt-get install xrdpsudo apt-get install vnc4server tightvncserver 安装字体sudo apt-get install ttf-wqy-zenhei 安装输入法sudo apt-get install fcitx fcitx-googlepinyin fcitx-module-cloudpinyin fcitx-sunpinyin]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[mongodb]]></title>
      <url>%2Fgithub_blog%2F2016%2F11%2F09%2F%E6%8A%80%E6%9C%AF%E5%AD%A6%E4%B9%A0%2F%E6%95%B0%E6%8D%AE%E5%BA%93%2Fmongodb%2F</url>
      <content type="text"><![CDATA[启动mongodb./mongod –dbpath ../dbpath/ –logpath ../logs/mongodb.log –logappend &amp; –fork show dbs 使用数据库mydbuse mydb 显示表show collections 查看表foo下的记录db.foo.find()]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[tomcat]]></title>
      <url>%2Fgithub_blog%2F2016%2F11%2F09%2F%E5%B7%A5%E5%85%B7%E4%BD%BF%E7%94%A8%2Ftomcat%2F</url>
      <content type="text"><![CDATA[远程调试Linxu系统: apach/bin/startup.sh开始处中增加如下内容： 1. declare -x CATALINA_OPTS=&quot;-server -Xdebug -Xnoagent -Djava.compiler=NONE -Xrunjdwp:transport=dt_socket,server=y,suspend=n,address=8788&quot; .Windows系统: apach/bin/startup.bat开始处中增加如下内容： 1. SET CATALINA_OPTS=-server -Xdebug -Xnoagent -Djava.compiler=NONE -Xrunjdwp:transport=dt_socket,server=y,suspend=n,address=8788 tomcat 配置域名到多个工程目录配置tomcat server.xml host appbase]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[树莓派常用命令]]></title>
      <url>%2Fgithub_blog%2F2016%2F11%2F09%2F%E6%8A%80%E6%9C%AF%E5%AD%A6%E4%B9%A0%2F%E6%A0%91%E8%8E%93%E6%B4%BE%2F%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%2F</url>
      <content type="text"><![CDATA[树莓派常用命令以某个用户身份运行程序1runuser -l pi -c &quot;command&quot;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[mysql]]></title>
      <url>%2Fgithub_blog%2F2016%2F11%2F09%2F%E6%8A%80%E6%9C%AF%E5%AD%A6%E4%B9%A0%2F%E6%95%B0%E6%8D%AE%E5%BA%93%2Fmysql%2F</url>
      <content type="text"><![CDATA[[TOC] mysql启动服务启动mysql：方式一：sudo /etc/init.d/mysql start方式二：sudo start mysql方式三：sudo service mysql start 停止mysql：方式一：sudo /etc/init.d/mysql stop方式二：sudo stop mysql方式san：sudo service mysql stop 重启mysql：方式一：sudo/etc/init.d/mysql restart方式二：sudo restart mysql方式三：sudo service mysql restart * 以root用户登入 mysql -u root -p 创建普通用户create user ‘salt’@’localhost’;set password for ‘salt’@’localhost’ = password(‘salt’); 创建数据库create database UGDAP; 显示所有数据库show databases; 为用户salt授予数据库UGDAP下所有表打所有权限grant all privileges on UGDAP.* to salt@localhost identified by ‘salt’;flush privileges; 以salt用户登入（远程登入）mysql -u salt -psaltmysql -h 192.168.200.213 -P 3306 -usalt -psalt 使用指定数据库use UGDAP; 查看所有表show tables; 删除库和表drop database 库名;drop table 表名； 将表中记录清空delete from 表名; 创建表create table tb_emp1( id INT(11), name VARCHAR(25), deptid INT (11), salary FLOAT); 显示表结构describe tb_emp1; 导入sql/执行sql脚本（shell中以及mysql中）mysql db_name &lt; text_filemysql db_name -u username -p &lt; text_file mysql&gt; source file_namemysql&gt; . file_name 导出数据库mysqldump -h 192.168.200.213 -P 3306 -usalt -psalt –default-character-set=utf8 UGDAP&gt;./UGDAP.sql 卸载mysql1234567891011121314151617181920sudo rm /var/lib/mysql/ -R//删除mysql的数据文件sudo rm /etc/mysql/ -R//删除mqsql的配置文件sudo apt-get autoremove mysql* --purgesudo apt-get remove apparmorsudo apt-get autoremove1 sudo apt-get autoremove --purge mysql-server-5.02 sudo apt-get remove mysql-server3 sudo apt-get autoremove mysql-server4 sudo apt-get remove mysql-common (非常重要)dpkg -l |grep ^rc|awk &apos;&#123;print $2&#125;&apos; |sudo xargs dpkg -P * 安装 mysql 1 sudo apt-get install mysql-server2 sudo apt-get install mysql-client3 sudo apt-get install php5-mysql(安装php5-mysql 是将php和mysql连接起来 ) 一旦安装完成，MySQL 服务器应该自动启动。您可以在终端提示符后运行以下命令来检查 MySQL 服务器是否正在运行：1 sudo netstat -tap | grep mysql 当您运行该命令时，您可以看到类似下面的行：tcp 0 0 localhost.localdomain:mysql : LISTEN -如果服务器不能正常运行，您可以通过下列命令启动它： 1 sudo /etc/init.d/mysql restart 修改root用户密码###第一步：修改Mysql配置文件[root@liama01 ~]# vi /etc/my.cnf在mysqld下，加入12skip-grant-tablesskip-networking ###第二步：重启Mysql后使用mysql -uroot -p 命令登入Mysql并修改密码123456service mysqld restartmysql -uroot -p 回车mysql&gt; use mysqlmysql&gt; update user set password=PASSWORD(&apos;root&apos;) WHERE user=&quot;root&quot;;mysql&gt; flush privileges; ###第三步：去掉跳过，并重启服务 123vi /etc/my.cnf去掉skip-grant-tables和skip-networkingservice mysqld restart ###第四步：重置密码如果不重置会报错 ERROR 1820 (HY000): You must reset your password using ALTER USER statement before executing this statement.执行重新设置密码mysql&gt; ALTER USER ‘root’@’localhost’ IDENTIFIED BY ‘**‘ 一条命令登录mysql 执行sql语句，然后退出mysql -h ip -uuser -ppwd -e”select * from bdpops.t_static_data limit 1”]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[mysql sql语法]]></title>
      <url>%2Fgithub_blog%2F2016%2F11%2F09%2F%E6%8A%80%E6%9C%AF%E5%AD%A6%E4%B9%A0%2F%E6%95%B0%E6%8D%AE%E5%BA%93%2Fmysql%20%E8%AF%AD%E6%B3%95%2F</url>
      <content type="text"><![CDATA[mysql 语句返回players表中town列所有数据项打集合以’,’分割的集合SELECT group_concat(town) FROM players group by town 获取符合条件的记录个数，表头为countselect count(*) as count from t_cluster_config_xml where cluster_name = ‘alto’ 如果存在则不插入insert into t_cluster_config_xml(a,b)select a,b from DUAL WHERE NOT EXISTS(SELECT a FROM t_cluster_config_xml WHERE a = ‘a’); 建表字符格式及长度 CHAR(M) [BINARY]一个定长字符串，当存储时，总是是用空格填满右边到指定的长度。M的范围是1 ～ 255个字符。当值被检索时，空格尾部被删除。CHAR值根据缺省字符集以大小写不区分的方式排序和比较，除非给出BINARY关键词。NATIONAL CHAR（短形式NCHAR)是ANSI SQL的方式来定义CHAR列应该使用缺省字符集。这是MySQL的缺省。CHAR是CHARACTER的一个缩写。 TINYBLOB TINYTEXT一个BLOB或TEXT列，最大长度为255(2^8-1)个字符。 BLOB TEXT一个BLOB或TEXT列，最大长度为65535(2^16-1)个字符。 MEDIUMBLOB MEDIUMTEXT一个BLOB或TEXT列，最大长度为16777215(2^24-1)个字符。 LONGBLOB LONGTEXT一个BLOB或TEXT列，最大长度为4294967295(2^32-1)个字符。 数值类型长度(M)的含义原文m 不是表示的数据长度，而是表示数据在显示时显示的最小长度。当字符长度超过(m)时，相当于啥都没发生；当字符长度小于(m)时，就需要指定拿某个字符来填充，比如zerofill（表示用0填充），设置tinyint(2) zerofill 你插入1时他会显示01；设置tinyint(4) zerofill 你插入1时他会显示0001。所以，没有zerofill，(m)就是无用的。 真相在这里 类型 长度 范围 名称 TINYINT 1字节 (-128，127) (0，255) 小整数值 SMALLINT 2 字节 ( -2^15 ：-32 768，2^15 - 1：32 767) (0，65 535) 大整数值 MEDIUMINT 3 字节 (-8 388 608，8 388 607) (0，16 777 215) 大整数值 INT或INTEGER 4 字节 (-2^31， 2^31 - 1) (0，4 294 967 295) 大整数值 BIGINT 8 字节 (-2^63，2^63-1) (0，18 446 744 073 709 551 615) 极大整数值]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[vim]]></title>
      <url>%2Fgithub_blog%2F2016%2F11%2F09%2F%E5%B7%A5%E5%85%B7%E4%BD%BF%E7%94%A8%2Fvim%2F</url>
      <content type="text"><![CDATA[vim设置粘贴可以500行 1. :set viminfo=&apos;1000,&lt;500 整体下移：ctrl + e整体上移 : ctrl + y 显示行号：set nu vim配置文件：/etc/vim/vimrc 查找字符串 ?内容 N下一个 n上一个 配置文件位置vim /etc/vimrc 设置粘贴模式 粘贴模式可以不带缩进粘贴 set paste set nopaste 也可以在.vimrc中设置切换的快捷键，比如设置F9，则可以在.vimrc中加入： set pastetoggle=&lt;F9&gt;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[kafka]]></title>
      <url>%2Fgithub_blog%2F2016%2F11%2F09%2F%E6%8A%80%E6%9C%AF%E5%AD%A6%E4%B9%A0%2Fkafka%2F</url>
      <content type="text"><![CDATA[启动zookeeper1bin/zookeeper-server-start.sh config/zookeeper.properties &amp; 启动KAFKA1bin/kafka-server-start.sh config/server.properties &amp; 模拟consumer1bin/kafka-console-consumer.sh --zookeeper 127.0.0.1:2181 --from-beginning --topic self_healing]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[hadoop 命令]]></title>
      <url>%2Fgithub_blog%2F2016%2F11%2F09%2F%E6%8A%80%E6%9C%AF%E5%AD%A6%E4%B9%A0%2Fbigdata%2Fhadoop%2Fhadoop%2F</url>
      <content type="text"><![CDATA[显示loghadoop fs -cat /tmp/app-logs/prestotest/logs/application_1460457323828_0044/BJHC-Client-77104.hadoop.jd.local_50086 创建文件夹hadoop fs -mkdir /user/admin/aaron/newDir 上传文件hadoop fs –put /home/admin/newFile /user/admin/aaron/ 下载文件hadoop fs –get /user/admin/aaron/newFile /home/admin/newFile 显示所有jobhadoop job -list]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[etcd]]></title>
      <url>%2Fgithub_blog%2F2016%2F11%2F09%2F%E6%8A%80%E6%9C%AF%E5%AD%A6%E4%B9%A0%2Fetcd%2F</url>
      <content type="text"><![CDATA[介绍etcd是一个高可用的键值存储系统，主要用于共享配置和服务发现。etcd是由CoreOS开发并维护的，灵感来自于 ZooKeeper 和 Doozer，它使用Go语言编写，并通过Raft一致性算法处理日志复制以保证强一致性。Raft是一个来自Stanford的新的一致性算法，适用于分布式系统的日志复制，Raft通过选举的方式来实现一致性，在Raft中，任何一个节点都可能成为Leader。Google的容器集群管理系统Kubernetes、开源PaaS平台Cloud Foundry和CoreOS的Fleet都广泛使用了etcd。 etcd 集群的工作原理基于 raft 共识算法 (The Raft Consensus Algorithm)。etcd 在 0.5.0 版本中重新实现了 raft 算法，而非像之前那样依赖于第三方库 go-raft 。raft 共识算法的优点在于可以在高效的解决分布式系统中各个节点日志内容一致性问题的同时，也使得集群具备一定的容错能力。即使集群中出现部分节点故障、网络故障等问题，仍可保证其余大多数节点正确的步进。甚至当更多的节点（一般来说超过集群节点总数的一半）出现故障而导致集群不可用时，依然可以保证节点中的数据不会出现错误的结果。 设置值，允许目录不存在curl -x 172.22.91.78:80 -X PUT http://172.22.77.107:2379/v2/keys/presto/clustertest/y2/worker2/bbb -d value=”sss”|python -m json.tool 删除空目录 curl -X DELETE -x 172.22.91.78:80 http://172.22.77.109:2379/v2/keys/presto/clustertest/66?dir=true|python -m json.tool 删除目录所有内容 curl -X DELETE -x 172.22.91.78:80 http://172.22.77.109:2379/v2/keys/presto/clustertest/66?recursive=true|python -m json.tool 获取成员curl -x 172.22.91.78:80 -H “Content-type: application/json” http://172.22.77.109:2379/v2/members|python -m json.tool 查看是否leadercurl -x 172.22.91.78:80 -H “Content-type: application/json” http://172.22.77.108:2379/v2/stats/self |python -m json.toolcurl -x 172.22.91.78:80 -H “Content-type: application/json” http://172.22.77.107:2379/v2/stats/leader|python -m json.tool 查看是否健康curl -x 172.22.91.78:80 -H “Content-type: application/json” http://172.22.77.107:2379/health|python -m json.tool]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[hadoop_rest]]></title>
      <url>%2Fgithub_blog%2F2016%2F11%2F09%2F%E6%8A%80%E6%9C%AF%E5%AD%A6%E4%B9%A0%2Fbigdata%2Fhadoop%2Fhadoop_rest%2F</url>
      <content type="text"><![CDATA[curl -x 172.22.91.78:80 -X GET -H “Accept:application/xml” http://172.16.172.95:19888/ws/v1/history/mapreduce/jobs/job_1470405196301_64396 curl -x 172.22.91.78:80 -X GET -H “Accept:application/json” http://172.16.172.95:19888/ws/v1/history/mapreduce/jobs/job_1470405196301_64396|python -m json.tool]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[fair-scheduler]]></title>
      <url>%2Fgithub_blog%2F2016%2F11%2F09%2F%E6%8A%80%E6%9C%AF%E5%AD%A6%E4%B9%A0%2Fbigdata%2Fhadoop%2Fyarn%2Ffair-scheduler%2F</url>
      <content type="text"><![CDATA[fair-scheduler.xml的配置在一个公司内部的Hadoop Yarn集群，肯定会被多个业务、多个用户同时使用，共享Yarn的资源，如果不做资源的管理与规划，那么整个Yarn的资源很容易被某一个用户提交的Application占满，其它任务只能等待，这种当然很不合理，我们希望每个业务都有属于自己的特定资源来运行MapReduce任务，Hadoop中提供的公平调度器–Fair Scheduler，就可以满足这种需求。 Fair Scheduler将整个Yarn的可用资源划分成多个资源池，每个资源池中可以配置最小和最大的可用资源（内存和CPU）、最大可同时运行Application数量、权重、以及可以提交和管理Application的用户等。 根据用户名分配资源池 如图所示，假设整个Yarn集群的可用资源为100vCPU，100GB内存，现在为3个业务各自规划一个资源池，另外，规划一个default资源池，用于运行其他用户和业务提交的任务。如果没有在任务中指定资源池（通过参数mapreduce.job.queuename），那么可以配置使用用户名作为资源池名称来提交任务，即用户businessA提交的任务被分配到资源池businessA中，用户businessC提交的任务被分配到资源池businessC中。除了配置的固定用户，其他用户提交的任务将会被分配到资源池default中。 这里的用户名，就是提交Application所使用的Linux/Unix用户名。 另外，每个资源池可以配置允许提交任务的用户名，比如，在资源池businessA中配置了允许用户businessA和用户lxw1234提交任务，如果使用用户lxw1234提交任务，并且在任务中指定了资源池为businessA，那么也可以正常提交到资源池businessA中。 根据权重获得额外的空闲资源在每个资源池的配置项中，有个weight属性（默认为1），标记了资源池的权重，当资源池中有任务等待，并且集群中有空闲资源时候，每个资源池可以根据权重获得不同比例的集群空闲资源。 比如，资源池businessA和businessB的权重分别为2和1，这两个资源池中的资源都已经跑满了，并且还有任务在排队，此时集群中有30个Container的空闲资源，那么，businessA将会额外获得20个Container的资源，businessB会额外获得10个Container的资源。 最小资源保证在每个资源池中，允许配置该资源池的最小资源，这是为了防止把空闲资源共享出去还未回收的时候，该资源池有任务需要运行时候的资源保证。 比如，资源池businessA中配置了最小资源为（5vCPU，5GB），那么即使没有任务运行，Yarn也会为资源池businessA预留出最小资源，一旦有任务需要运行，而集群中已经没有其他空闲资源的时候，这个最小资源也可以保证资源池businessA中的任务可以先运行起来，随后再从集群中获取资源。 动态更新资源配额Fair Scheduler除了需要在yarn-site.xml文件中启用和配置之外，还需要一个XML文件来配置资源池以及配额，而该XML中每个资源池的配额可以动态更新，之后使用命令：yarn rmadmin –refreshQueues 来使得其生效即可，不用重启Yarn集群。 需要注意的是：动态更新只支持修改资源池配额，如果是新增或减少资源池，则需要重启Yarn集群。 1. 配置文件yarn-site.xml （1） yarn.scheduler.fair.allocation.file ：自定义XML配置文件所在位置，该文件主要用于描述各个队列的属性，比如资源量、权重等，具体配置格式将在后面介绍。 （2） yarn.scheduler.fair.user-as-default-queue：当应用程序未指定队列名时，是否指定用户名作为应用程序所在的队列名。如果设置为false或者未设置，所有未知队列的应用程序将被提交到default队列中，默认值为true。 （3） yarn.scheduler.fair.preemption：是否启用抢占机制，默认值是false。 （4） yarn.scheduler.fair.sizebasedweight：在一个队列内部分配资源时，默认情况下，采用公平轮询的方法将资源分配各各个应用程序，而该参数则提供了另外一种资源分配方式：按照应用程序资源需求数目分配资源，即需求资源数量越多，分配的资源越多。默认情况下，该参数值为false。 （5） yarn.scheduler.assignmultiple：是否启动批量分配功能。当一个节点出现大量资源时，可以一次分配完成，也可以多次分配完成。默认情况下，该参数值为false。 （6） yarn.scheduler.fair.max.assign：如果开启批量分配功能，可指定一次分配的container数目。默认情况下，该参数值为-1，表示不限制。 （7） yarn.scheduler.fair.locality.threshold.node：当应用程序请求某个节点上资源时，它可以接受的可跳过的最大资源调度机会。当按照分配策略，可将一个节点上的资源分配给某个应用程序时，如果该节点不是应用程序期望的节点，可选择跳过该分配机会暂时将资源分配给其他应用程序，直到出现满足该应用程序需的节点资源出现。通常而言，一次心跳代表一次调度机会，而该参数则表示跳过调度机会占节点总数的比例，默认情况下，该值为-1.0，表示不跳过任何调度机会。 （8） yarn.scheduler.fair.locality.threshold.rack：当应用程序请求某个机架上资源时，它可以接受的可跳过的最大资源调度机会。 （9） yarn.scheduler.increment-allocation-mb：内存规整化单位，默认是1024，这意味着，如果一个Container请求资源是1.5GB，则将被调度器规整化为ceiling(1.5 GB / 1GB) * 1G=2GB。 （10） yarn.scheduler.increment-allocation-vcores：虚拟CPU规整化单位，默认是1，含义与内存规整化单位类似。 2. 自定义配置文件 Fair Scheduler允许用户将队列信息专门放到一个配置文件（默认是fair-scheduler.xml），对于每个队列，管理员可配置以下几个选项： （1） minResources ：最少资源保证量，设置格式为“X mb, Y vcores”，当一个队列的最少资源保证量未满足时，它将优先于其他同级队列获得资源，对于不同的调度策略（后面会详细介绍），最少资源保证量的含义不同，对于fair策略，则只考虑内存资源，即如果一个队列使用的内存资源超过了它的最少资源量，则认为它已得到了满足；对于drf策略，则考虑主资源使用的资源量，即如果一个队列的主资源量超过它的最少资源量，则认为它已得到了满足。 （2） maxResources：最多可以使用的资源量，fair scheduler会保证每个队列使用的资源量不会超过该队列的最多可使用资源量。 （3） maxRunningApps：最多同时运行的应用程序数目。通过限制该数目，可防止超量Map Task同时运行时产生的中间输出结果撑爆磁盘。 （4） minSharePreemptionTimeout：最小共享量抢占时间。如果一个资源池在该时间内使用的资源量一直低于最小资源量，则开始抢占资源。 （5） schedulingMode/schedulingPolicy：队列采用的调度模式，可以是fifo、fair或者drf。 （6） aclSubmitApps：可向队列中提交应用程序的Linux用户或用户组列表，默认情况下为“*”，表示任何用户均可以向该队列提交应用程序。需要注意的是，该属性具有继承性，即子队列的列表会继承父队列的列表。配置该属性时，用户之间或用户组之间用“，”分割，用户和用户组之间用空格分割，比如“user1, user2 group1,group2”。 （7） aclAdministerApps：该队列的管理员列表。一个队列的管理员可管理该队列中的资源和应用程序，比如可杀死任意应用程序。 管理员也可为单个用户添加maxRunningJobs属性限制其最多同时运行的应用程序数目。此外，管理员也可通过以下参数设置以上属性的默认值： （1） userMaxJobsDefault：用户的maxRunningJobs属性的默认值。 （2） defaultMinSharePreemptionTimeout ：队列的minSharePreemptionTimeout属性的默认值。 （3） defaultPoolSchedulingMode：队列的schedulingMode属性的默认值。 （4） fairSharePreemptionTimeout：公平共享量抢占时间。如果一个资源池在该时间内使用资源量一直低于公平共享量的一半，则开始抢占资源。]]></content>
    </entry>

    
  
  
</search>
